{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch 선형회귀",
      "provenance": [],
      "authorship_tag": "ABX9TyMtbdTK/J92I27F7DB7j2Dp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sukhyun1017/pytorch-study/blob/main/pytorch_%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%801.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bfPptu976wo4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXiiGQle67oI",
        "outputId": "a268a940-a7ca-4e0f-f1df-e7b713fb07c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd9c5ba7dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])"
      ],
      "metadata": {
        "id": "zmebyNoQ6-Gk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx5SkqdD7N48",
        "outputId": "37421b73-359b-4cf1-ffbf-322a2b342af7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W=torch.zeros(1,requires_grad=True) #requires_grad=True => 자동미분\n",
        "print(W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a35vMkEy7TdZ",
        "outputId": "184f414c-5f4d-4bdb-ce63-6b44f653fc0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b=torch.zeros(1,requires_grad=True)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONAqEEW67qmr",
        "outputId": "715438ef-5c36-4a3f-eab6-dfecfae6d4cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H=x_train*W+b\n",
        "print(H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXVB2vU97zFW",
        "outputId": "0b7eea5c-10b7-4736-d689-f1441b94b49c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost=torch.mean((H-y_train)**2)\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDINEv6_77fe",
        "outputId": "e0f8dc82-b187-42e6-cc76-80a7b5bbd631"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "경사하강법 구현"
      ],
      "metadata": {
        "id": "QIIblcpv8lxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])\n",
        "W=torch.zeros(1,requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)\n",
        "H=x_train*W+b\n",
        "cost=torch.mean((H-y_train)**2)\n",
        "\n",
        "optimizer = optim.SGD([W,b],lr=0.01)\n",
        "nb_epochs=1000\n",
        "for epoch in range(nb_epochs +1):\n",
        "  H = x_train*W + b\n",
        "  cost=torch.mean((H-y_train)**2)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100 ==0:\n",
        "    print('Epoch {:4d}/{} W:{:.3f},b: {:.3f} Cost: {:.6f}'.format(epoch,nb_epochs,W.item(),b.item(),cost.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlk45q_i8s2U",
        "outputId": "8e92fb93-8c46-4c75-e8c5-beef7ae73d71"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 W:0.187,b: 0.080 Cost: 18.666666\n",
            "Epoch  100/1000 W:1.746,b: 0.578 Cost: 0.048171\n",
            "Epoch  200/1000 W:1.800,b: 0.454 Cost: 0.029767\n",
            "Epoch  300/1000 W:1.843,b: 0.357 Cost: 0.018394\n",
            "Epoch  400/1000 W:1.876,b: 0.281 Cost: 0.011366\n",
            "Epoch  500/1000 W:1.903,b: 0.221 Cost: 0.007024\n",
            "Epoch  600/1000 W:1.924,b: 0.174 Cost: 0.004340\n",
            "Epoch  700/1000 W:1.940,b: 0.136 Cost: 0.002682\n",
            "Epoch  800/1000 W:1.953,b: 0.107 Cost: 0.001657\n",
            "Epoch  900/1000 W:1.963,b: 0.084 Cost: 0.001024\n",
            "Epoch 1000/1000 W:1.971,b: 0.066 Cost: 0.000633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])\n",
        "W=torch.zeros(1,requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)\n",
        "H=x_train*W+b\n",
        "cost=torch.mean((H-y_train)**2)\n",
        "\n",
        "optimizer = optim.Adam([W,b],lr=0.01)\n",
        "nb_epochs=1000\n",
        "for epoch in range(nb_epochs +1):\n",
        "  H = x_train*W + b\n",
        "  cost=torch.mean((H-y_train)**2)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100 ==0:\n",
        "    print('Epoch {:4d}/{} W:{:.3f},b: {:.3f} Cost: {:.6f}'.format(epoch,nb_epochs,W.item(),b.item(),cost.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnW4VXGh94_-",
        "outputId": "5e5a05fe-dd96-47e2-8c97-e1ef983485b8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 W:0.010,b: 0.010 Cost: 18.666666\n",
            "Epoch  100/1000 W:0.857,b: 0.847 Cost: 3.003903\n",
            "Epoch  200/1000 W:1.275,b: 1.210 Cost: 0.414147\n",
            "Epoch  300/1000 W:1.412,b: 1.250 Cost: 0.236496\n",
            "Epoch  400/1000 W:1.465,b: 1.182 Cost: 0.203832\n",
            "Epoch  500/1000 W:1.507,b: 1.093 Cost: 0.173795\n",
            "Epoch  600/1000 W:1.550,b: 0.998 Cost: 0.145013\n",
            "Epoch  700/1000 W:1.593,b: 0.902 Cost: 0.118445\n",
            "Epoch  800/1000 W:1.636,b: 0.807 Cost: 0.094712\n",
            "Epoch  900/1000 W:1.678,b: 0.713 Cost: 0.074131\n",
            "Epoch 1000/1000 W:1.718,b: 0.624 Cost: 0.056778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])\n",
        "W=torch.zeros(1,requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)\n",
        "H=x_train*W+b\n",
        "cost=torch.mean((H-y_train)**2)\n",
        "\n",
        "optimizer = optim.AdamW([W,b],lr=0.01)\n",
        "nb_epochs=1000\n",
        "for epoch in range(nb_epochs +1):\n",
        "  H = x_train*W + b\n",
        "  cost=torch.mean((H-y_train)**2)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100 ==0:\n",
        "    print('Epoch {:4d}/{} W:{:.3f},b: {:.3f} Cost: {:.6f}'.format(epoch,nb_epochs,W.item(),b.item(),cost.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylLVSDrF-3gF",
        "outputId": "79be0ac4-b5ed-420c-e3d7-7207432cacc1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 W:0.010,b: 0.010 Cost: 18.666666\n",
            "Epoch  100/1000 W:0.853,b: 0.843 Cost: 3.042728\n",
            "Epoch  200/1000 W:1.266,b: 1.203 Cost: 0.434577\n",
            "Epoch  300/1000 W:1.403,b: 1.244 Cost: 0.240859\n",
            "Epoch  400/1000 W:1.456,b: 1.180 Cost: 0.206266\n",
            "Epoch  500/1000 W:1.497,b: 1.095 Cost: 0.176742\n",
            "Epoch  600/1000 W:1.539,b: 1.004 Cost: 0.148671\n",
            "Epoch  700/1000 W:1.581,b: 0.913 Cost: 0.122769\n",
            "Epoch  800/1000 W:1.623,b: 0.822 Cost: 0.099581\n",
            "Epoch  900/1000 W:1.663,b: 0.734 Cost: 0.079381\n",
            "Epoch 1000/1000 W:1.702,b: 0.649 Cost: 0.062222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FxkQmIgC-yv3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
